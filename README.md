# GPU Docker å¼€å‘ç¯å¢ƒ

ä¸€ä¸ªæ”¯æŒGPUçš„ç‹¬ç«‹Dockerå¼€å‘ç¯å¢ƒï¼Œé›†æˆäº†VSCode Serverã€Jupyter Labã€TensorBoardå’ŒSSHæœåŠ¡ï¼Œæ”¯æŒå¤šç”¨æˆ·å’Œç¯å¢ƒå˜é‡é…ç½®ã€‚

## ğŸš€ ç‰¹æ€§

- **GPUæ”¯æŒ**: åŸºäºNVIDIA CUDA 11.8é•œåƒï¼Œæ”¯æŒGPUåŠ é€Ÿ
- **å¤šæœåŠ¡é›†æˆ**: VSCode Server + Jupyter Lab + TensorBoard + SSH
- **å¤šç”¨æˆ·æ”¯æŒ**: é€šè¿‡ç¯å¢ƒå˜é‡é…ç½®ä¸åŒç”¨æˆ·
- **çµæ´»é…ç½®**: æ”¯æŒè‡ªå®šä¹‰ç”¨æˆ·IDã€å¯†ç ã€å·¥ä½œç›®å½•ç­‰
- **æŒä¹…åŒ–å­˜å‚¨**: ç”¨æˆ·æ•°æ®æŒä¹…åŒ–ä¿å­˜
- **å¼€ç®±å³ç”¨**: é¢„è£…æ·±åº¦å­¦ä¹ å¸¸ç”¨åº“

## ğŸ“¦ é¢„è£…è½¯ä»¶

- **å¼€å‘ç¯å¢ƒ**: VSCode Server, SSH, Git, Vim
- **Pythonç”Ÿæ€**: Python 3.12, Miniconda, Jupyter Lab
- **æ·±åº¦å­¦ä¹ **: PyTorch (CUDA 12.4), TensorBoard, Transformers, DGL, PyTorch Geometric
- **ç§‘å­¦è®¡ç®—**: NumPy, SciPy, SymPy, JAX, Numba, Dask
- **æ•°æ®ç§‘å­¦**: Pandas, Polars, Scikit-learn, XGBoost, LightGBM, Statsmodels
- **å¯è§†åŒ–**: Matplotlib, Seaborn, Plotly, Bokeh, Mayavi, VTK, py3Dmol
- **åŒ–å­¦ä¿¡æ¯å­¦**: RDKit, DeepChem, ASE, Pymatgen, OpenBabel
- **ç”Ÿç‰©ä¿¡æ¯å­¦**: BioPython, Scanpy, AnnData, MDTraj
- **ä¼˜åŒ–å·¥å…·**: CVXPY, Ray
- **ä¸“ä¸šå·¥å…·**: Mendeleev, PeriodTable, Pint (å•ä½è½¬æ¢)
- **å…¶ä»–**: OpenCV, W&B, Accelerate, Diffusers

## ğŸ›  å¿«é€Ÿå¼€å§‹

### æ–¹æ³•1: ä½¿ç”¨ä¾¿æ·è„šæœ¬ï¼ˆæ¨èï¼‰

```bash
# ç»™è„šæœ¬æ‰§è¡Œæƒé™
chmod +x run-container.sh

# å¯åŠ¨é»˜è®¤ç”¨æˆ·ç¯å¢ƒ
./run-container.sh

# å¯åŠ¨è‡ªå®šä¹‰ç”¨æˆ·ç¯å¢ƒ
./run-container.sh myuser mypassword ./my-workspace 90
```

### æ–¹æ³•2: ä½¿ç”¨Dockerå‘½ä»¤

```bash
# æ„å»ºé•œåƒ
docker build -t gpu-dev-env:latest .

# è¿è¡Œå®¹å™¨
docker run -d \
    --name gpu-dev-myuser \
    --gpus all \
    -p 8080:8080 \
    -p 8888:8888 \
    -p 6006:6006 \
    -p 2222:22 \
    -e DEV_USER=myuser \
    -e DEV_PASSWORD=mypassword \
    -e DEV_UID=$(id -u) \
    -e DEV_GID=$(id -g) \
    -v ./workspace:/home/myuser/workspace:rw \
    -v ./shared:/shared:ro \
    --shm-size=32g \
    gpu-dev-env:latest
```

### æ–¹æ³•3: ä½¿ç”¨Docker Composeï¼ˆå¤šç”¨æˆ·ï¼‰

```bash
# å¯åŠ¨å¤šç”¨æˆ·ç¯å¢ƒ
docker-compose up -d

# åœæ­¢ç¯å¢ƒ
docker-compose down
```

## ğŸŒ è®¿é—®æœåŠ¡

å¯åŠ¨åå¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼è®¿é—®å„é¡¹æœåŠ¡ï¼š

> **è·å–å®¿ä¸»æœºIPåœ°å€**ï¼š
> - Linux/macOS: `hostname -I | awk '{print $1}'` æˆ– `ip addr show | grep 'inet ' | grep -v '127.0.0.1' | awk '{print $2}' | cut -d'/' -f1 | head -n1`
> - Windows: `ipconfig` æŸ¥çœ‹IPv4åœ°å€
> - æœ¬åœ°å¼€å‘å¯ä»¥ä½¿ç”¨ `localhost` æˆ– `127.0.0.1`

| æœåŠ¡ | é»˜è®¤ç«¯å£ | è®¿é—®åœ°å€ |
|------|---------|----------|
| VSCode Server | 8080 | http://`<å®¿ä¸»æœºIP>`:8080 |
| Jupyter Lab | 8888 | http://`<å®¿ä¸»æœºIP>`:8888 |
| TensorBoard | 6006 | http://`<å®¿ä¸»æœºIP>`:6006 |
| SSH | 22 | `ssh -p 22 ç”¨æˆ·å@<å®¿ä¸»æœºIP>` |

## âš™ï¸ ç¯å¢ƒå˜é‡é…ç½®

| å˜é‡å | é»˜è®¤å€¼ | è¯´æ˜ |
|--------|--------|------|
| `DEV_USER` | devuser | å®¹å™¨å†…ç”¨æˆ·å |
| `DEV_PASSWORD` | changeme | ç”¨æˆ·å¯†ç ï¼ˆç”¨äºVSCodeã€Jupyterã€SSHï¼‰ |
| `DEV_UID` | 1000 | ç”¨æˆ·UIDï¼ˆå»ºè®®è®¾ç½®ä¸ºå®¿ä¸»æœºç”¨æˆ·UIDï¼‰ |
| `DEV_GID` | 1000 | ç”¨æˆ·GIDï¼ˆå»ºè®®è®¾ç½®ä¸ºå®¿ä¸»æœºç”¨æˆ·GIDï¼‰ |
| `ENABLE_JUPYTER` | true | æ˜¯å¦å¯ç”¨Jupyter Lab |
| `ENABLE_TENSORBOARD` | true | æ˜¯å¦å¯ç”¨TensorBoard |
| `WORKSPACE_DIR` | /home/ç”¨æˆ·å/workspace | å·¥ä½œç›®å½•è·¯å¾„ |

## ğŸ“ ç›®å½•ç»“æ„

```
gpu-docker/
â”œâ”€â”€ Dockerfile              # ä¸»é•œåƒå®šä¹‰
â”œâ”€â”€ docker-compose.yml      # å¤šç”¨æˆ·ç¼–æ’æ–‡ä»¶
â”œâ”€â”€ run-container.sh        # å¿«é€Ÿå¯åŠ¨è„šæœ¬
â”œâ”€â”€ entrypoint.sh           # å®¹å™¨å…¥å£è„šæœ¬
â”œâ”€â”€ supervisord.conf        # æœåŠ¡ç®¡ç†é…ç½®
â”œâ”€â”€ config/                 # é…ç½®æ–‡ä»¶ç›®å½•
â”‚   â””â”€â”€ code-server/
â”‚       â””â”€â”€ config.yaml     # VSCode Serveré…ç½®
â”œâ”€â”€ scripts/                # è¾…åŠ©è„šæœ¬
â”‚   â””â”€â”€ start-services.sh   # æœåŠ¡å¯åŠ¨è„šæœ¬
â”œâ”€â”€ data/                   # ç”¨æˆ·æ•°æ®ç›®å½•ï¼ˆè‡ªåŠ¨åˆ›å»ºï¼‰
â”‚   â”œâ”€â”€ user1/             # ç”¨æˆ·1å·¥ä½œç©ºé—´
â”‚   â””â”€â”€ user2/             # ç”¨æˆ·2å·¥ä½œç©ºé—´
â””â”€â”€ shared/                # å…±äº«æ•°æ®ç›®å½•
```

## ğŸ”§ ä½¿ç”¨ç¤ºä¾‹

### å•ç”¨æˆ·å¿«é€Ÿå¯åŠ¨

```bash
# å¯åŠ¨ç”¨æˆ·aliceçš„å¼€å‘ç¯å¢ƒï¼Œç«¯å£å‰ç¼€90
./run-container.sh alice password123 ./alice-workspace 90

# è®¿é—®åœ°å€ï¼š
# VSCode: http://<å®¿ä¸»æœºIP>:9080
# Jupyter: http://<å®¿ä¸»æœºIP>:9088
# TensorBoard: http://<å®¿ä¸»æœºIP>:9006
# SSH: ssh -p 9022 alice@<å®¿ä¸»æœºIP>
```

### å¤šç”¨æˆ·å¹¶è¡Œä½¿ç”¨

```bash
# å¯åŠ¨ç”¨æˆ·1
./run-container.sh user1 pass1 ./data/user1 80

# å¯åŠ¨ç”¨æˆ·2  
./run-container.sh user2 pass2 ./data/user2 81

# ç”¨æˆ·1è®¿é—®ï¼šhttp://<å®¿ä¸»æœºIP>:8080
# ç”¨æˆ·2è®¿é—®ï¼šhttp://<å®¿ä¸»æœºIP>:8180
```

### GPUæµ‹è¯•

åœ¨Jupyteræˆ–VSCodeä¸­è¿è¡Œä»¥ä¸‹ä»£ç æµ‹è¯•GPUï¼š

```python
import torch
import numpy as np
import sys

# æ£€æŸ¥Pythonå’ŒCUDAç‰ˆæœ¬
print(f"Python version: {sys.version}")
print(f"PyTorch version: {torch.__version__}")
print(f"CUDA available: {torch.cuda.is_available()}")
print(f"CUDA device count: {torch.cuda.device_count()}")
if torch.cuda.is_available():
    print(f"Current device: {torch.cuda.current_device()}")
    print(f"Device name: {torch.cuda.get_device_name()}")
    print(f"CUDA version: {torch.version.cuda}")

# åˆ›å»ºGPUå¼ é‡è¿›è¡Œæµ‹è¯•
if torch.cuda.is_available():
    x = torch.randn(1000, 1000).cuda()
    y = torch.randn(1000, 1000).cuda()
    z = torch.mm(x, y)
    print(f"GPU calculation result shape: {z.shape}")
    print("GPU test completed successfully!")
```

### AI for Scienceå·¥å…·æµ‹è¯•

```python
# æµ‹è¯•ç§‘å­¦è®¡ç®—å·¥å…·
import numpy as np
import scipy
import jax.numpy as jnp
from jax import grad, jit
import sympy as sp

print("=== åŸºç¡€ç§‘å­¦è®¡ç®— ===")
print(f"NumPy version: {np.__version__}")
print(f"SciPy version: {scipy.__version__}")

# æµ‹è¯•JAX
@jit
def selu(x, alpha=1.67, lmbda=1.05):
    return lmbda * jnp.where(x > 0, x, alpha * jnp.exp(x) - alpha)

x = jnp.arange(1000000.0)
result = selu(x)
print(f"JAX computation completed: {result.shape}")

# æµ‹è¯•åŒ–å­¦ä¿¡æ¯å­¦
print("\n=== åŒ–å­¦ä¿¡æ¯å­¦ ===")
try:
    from rdkit import Chem
    from rdkit.Chem import Descriptors
    mol = Chem.MolFromSmiles('CCO')  # ä¹™é†‡
    print(f"åˆ†å­é‡: {Descriptors.MolWt(mol):.2f}")
    print("RDKitå·¥ä½œæ­£å¸¸")
except ImportError:
    print("RDKitæœªæ­£ç¡®å®‰è£…")

# æµ‹è¯•ææ–™ç§‘å­¦
print("\n=== ææ–™ç§‘å­¦ ===")
try:
    from pymatgen.core import Structure, Lattice
    from ase import Atoms
    print("ASEå’ŒPymatgenå·¥ä½œæ­£å¸¸")
except ImportError:
    print("ææ–™ç§‘å­¦å·¥å…·æœªæ­£ç¡®å®‰è£…")

# æµ‹è¯•å›¾ç¥ç»ç½‘ç»œ
print("\n=== å›¾ç¥ç»ç½‘ç»œ ===")
try:
    import torch_geometric
    import dgl
    print(f"PyTorch Geometric version: {torch_geometric.__version__}")
    print(f"DGL version: {dgl.__version__}")
except ImportError:
    print("å›¾ç¥ç»ç½‘ç»œåº“æœªæ­£ç¡®å®‰è£…")

# æµ‹è¯•ç”Ÿç‰©ä¿¡æ¯å­¦
print("\n=== ç”Ÿç‰©ä¿¡æ¯å­¦ ===")
try:
    from Bio.Seq import Seq
    dna = Seq("AGTACACTGGT")
    print(f"DNAåºåˆ—: {dna}")
    print(f"è½¬å½•RNA: {dna.transcribe()}")
    print("BioPythonå·¥ä½œæ­£å¸¸")
except ImportError:
    print("BioPythonæœªæ­£ç¡®å®‰è£…")

print("\n=== æµ‹è¯•å®Œæˆ ===")
```

## ğŸ›¡ï¸ å®‰å…¨æ³¨æ„äº‹é¡¹

1. **å¯†ç å®‰å…¨**: è¯·ä¿®æ”¹é»˜è®¤å¯†ç ï¼Œä½¿ç”¨å¼ºå¯†ç 
2. **ç«¯å£å®‰å…¨**: åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œå»ºè®®ä½¿ç”¨é˜²ç«å¢™é™åˆ¶ç«¯å£è®¿é—®
3. **æ•°æ®æƒé™**: ç¡®ä¿æŒ‚è½½ç›®å½•çš„æƒé™è®¾ç½®æ­£ç¡®
4. **ç½‘ç»œå®‰å…¨**: åœ¨å…¬ç½‘ç¯å¢ƒä¸­ä½¿ç”¨æ—¶ï¼Œå»ºè®®é…ç½®SSLè¯ä¹¦

## ğŸ” æ•…éšœæ’é™¤

### å®¹å™¨æ— æ³•å¯åŠ¨

```bash
# æŸ¥çœ‹å®¹å™¨æ—¥å¿—ï¼ˆæ›¿æ¢ä¸ºå®é™…ç”¨æˆ·åï¼Œå¦‚ï¼šgpu-dev-devuserï¼‰
docker logs gpu-dev-<ç”¨æˆ·å>

# æ£€æŸ¥GPUé©±åŠ¨
nvidia-smi

# æ£€æŸ¥Docker GPUæ”¯æŒï¼ˆä½¿ç”¨å½“å‰CUDAç‰ˆæœ¬ï¼‰
docker run --rm --gpus all nvidia/cuda:12.4.1-base nvidia-smi

# æ£€æŸ¥Dockeræ˜¯å¦æ­£å¸¸è¿è¡Œ
docker --version
docker ps
```

### æœåŠ¡æ— æ³•è®¿é—®

```bash
# æ£€æŸ¥ç«¯å£å ç”¨ï¼ˆLinux/macOSï¼‰
netstat -tlnp | grep :8080
# æˆ–è€…ä½¿ç”¨sså‘½ä»¤
ss -tlnp | grep :8080

# Windowsæ£€æŸ¥ç«¯å£å ç”¨
netstat -ano | findstr :8080

# æ£€æŸ¥å®¹å™¨æ˜¯å¦è¿è¡Œ
docker ps | grep gpu-dev

# è¿›å…¥å®¹å™¨è°ƒè¯•ï¼ˆæ›¿æ¢ä¸ºå®é™…å®¹å™¨åï¼‰
docker exec -it gpu-dev-<ç”¨æˆ·å> bash

# åœ¨å®¹å™¨å†…æ£€æŸ¥æœåŠ¡çŠ¶æ€
docker exec gpu-dev-<ç”¨æˆ·å> supervisorctl status

# é‡å¯ç‰¹å®šæœåŠ¡
docker exec gpu-dev-<ç”¨æˆ·å> supervisorctl restart code-server
docker exec gpu-dev-<ç”¨æˆ·å> supervisorctl restart jupyter
docker exec gpu-dev-<ç”¨æˆ·å> supervisorctl restart tensorboard

# é‡å¯æ‰€æœ‰æœåŠ¡
docker exec gpu-dev-<ç”¨æˆ·å> supervisorctl restart all
```

### æƒé™é—®é¢˜

```bash
# ä¿®å¤å·¥ä½œç›®å½•æƒé™ï¼ˆæ›¿æ¢ä¸ºå®é™…å·¥ä½œç›®å½•è·¯å¾„ï¼‰
sudo chown -R $(id -u):$(id -g) <å·¥ä½œç›®å½•è·¯å¾„>

# ç¤ºä¾‹ï¼š
sudo chown -R $(id -u):$(id -g) ./workspace
sudo chown -R $(id -u):$(id -g) ./data/user1
sudo chown -R $(id -u):$(id -g) ./shared
sudo chown -R $(id -u):$(id -g) ./tmp

# æ£€æŸ¥ç›®å½•æƒé™
ls -la ./workspace
ls -la ./shared
ls -la ./tmp
```

### å…±äº«å†…å­˜ä¸è¶³

```bash
# æ£€æŸ¥å®¹å™¨å†…å…±äº«å†…å­˜ä½¿ç”¨æƒ…å†µ
docker exec gpu-dev-<ç”¨æˆ·å> df -h /dev/shm

# å¦‚æœå‡ºç° "No space left on device" é”™è¯¯
# å¯ä»¥å°è¯•å¢åŠ å…±äº«å†…å­˜å¤§å°ï¼ˆåœ¨å¯åŠ¨æ—¶æ·»åŠ ï¼‰
--shm-size=64g  # æ ¹æ®éœ€è¦è°ƒæ•´å¤§å°
```

### å¸¸è§é”™è¯¯åŠè§£å†³æ–¹æ¡ˆ

**é”™è¯¯ï¼š`docker: Error response from daemon: could not select device driver "nvidia"`**
```bash
# è§£å†³æ–¹æ¡ˆï¼šå®‰è£…æˆ–é‡æ–°å®‰è£…NVIDIA Container Toolkit
# Ubuntu/Debian:
distribution=$(. /etc/os-release;echo $ID$VERSION_ID) \
   && curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add - \
   && curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list

sudo apt-get update
sudo apt-get install -y nvidia-docker2
sudo systemctl restart docker
```

**é”™è¯¯ï¼šç«¯å£å·²è¢«å ç”¨**
```bash
# æŸ¥æ‰¾å ç”¨ç«¯å£çš„è¿›ç¨‹
sudo lsof -i :8080
# ç»ˆæ­¢å ç”¨ç«¯å£çš„è¿›ç¨‹
sudo kill -9 <PID>
# æˆ–ä½¿ç”¨ä¸åŒçš„ç«¯å£å‰ç¼€å¯åŠ¨
./run-container.sh myuser password ./workspace 81  # ä½¿ç”¨81xxç«¯å£
```

## ğŸ“ å¼€å‘å»ºè®®

1. **å·¥ä½œç›®å½•**: å°†ä»£ç æ”¾åœ¨æŒ‚è½½çš„å·¥ä½œç›®å½•ä¸­ï¼Œç¡®ä¿æ•°æ®æŒä¹…åŒ–
2. **GPUå†…å­˜**: ä½¿ç”¨TensorBoardç›‘æ§GPUä½¿ç”¨æƒ…å†µ
3. **Jupyteræ’ä»¶**: å¯ä»¥å®‰è£…é¢å¤–çš„Jupyteræ‰©å±•
4. **VSCodeæ’ä»¶**: åœ¨VSCodeä¸­å®‰è£…Pythonã€Dockerç­‰æ‰©å±•

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤Issueå’ŒPull Requestæ¥æ”¹è¿›è¿™ä¸ªé¡¹ç›®ï¼

## ï¿½ï¿½ è®¸å¯è¯

MIT License 